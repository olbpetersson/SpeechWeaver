\chapter{Discussion}
\lettrine[lines=4, loversize=-0.1, lraise=0.1]{T}{he product developed during this thesis} introduces a new way of interacting with, and maintaining SRSs. Therefore, the concept is unexplored, and several findings were made during the development and evaluation of the product. This section will discuss these findings and possible outcomes of the concept. In the end of this section the authors will give their thoughts about the future work that could be applied to this thesis. 

\section{Implementation Discussion}
During the course of the thesis, several design decision were made. In this chapter we will discuss the affect that those decisions had on the result and the solution.

\subsection{Annotations - where?}
In the solutions presented in this thesis, the annotations are connected as meta-data to the requirement that the annotation is associated with. There are several advantages with this solution. When having the annotations as meta-data they are isolated from the requirements, something that enables the requirement to be intact. Another solution that was considered and discarded was to have the annotations as attributes on the requirement. However, this would not allow for isolation. Having the annotations as meta-data also allows an easy way for several annotations to the same requirement. When the annotations are isolated, they are light weight and disposable.

\subsection{Generelizability - SystemWeaver}
The platform that the solution was built on was an already existing application product line managing software - SystemWeaver. However, the solutions that are presented aims to be as general as possible. If you break it down, what is needed for this solution to work is a requirement database whom which you can query for individual and sets of requirements, and a way of creating and connecting issues to the queried requirements. In the solution presented, there are no special demands within the issue, nor the requirement, that is needed for the solution to work. However, SystemWeaver has proven to be very efficient. An equal solution for another system would of course give different results in terms of execution time dependent on the implementation of that system. 

\subsection{Levenshtein Edit Distance Algorithm}
\label{subsec:leved}
A core part of the improvement and adaption of spoken input in our solution is the string edit distance algorithm. The choice of using Levenshtein string edit distance algorithm affected the post-processing of the spoken input. Since the algorithm has the same weight on all operations (add, delete, modify) it makes the length of the strings a bigger influence. Although, as shown in the results (see Section~\ref{sub:reqmatch}), it gave satisfying results. However, it also disables the user to search for substrings, even if those are correctly interpreted by the speech recognizer. 

Searching for requirements using a matching algorithm works well when the user knows exactly what requirement to search for, but is a problem if they are searching for a requirement containing a particular substring. It could be the case that the user is looking for a requirement that has \emph{"acceleration"} in it, but the user does not remember the whole title. This could be solved with another search option looking for requirement titles containing exact substrings. However, using free text search requires more effort in terms of tweaking your search term to give few enough results and can be harder and more complex if you need to search for \emph{"gearbox AND clutch"}. This extra effort in terms of speed and complexity might be worth it if the use case for the product would develop towards a more look-up oriented approach. The use of string metric algorighm could be chosen differently, but the focus was not to evaluate string metric algorithms, the results from the experiment shows that using Levenshtein gives a good accuarcy increase, but other algorithms might be more accurate for requirement titles. Some other algorithms could be Jaro-Winkler, Soundex, N-grams or Jaccard. These different algorithms could give different benefits for longer or shorter names, some might handle misspellings better and some might suit special characters better.

\subsection{Android's speech recognizer}
The speech recognizer was considered a black box which provided the ability to interpret spoken words. In this thesis we chose to work with Android's provided speech-to-text engine. The solution is built upon handling strings, something that makes the solution general for any speech-to-text engine. However, the "perfect-match" algorithm that was implemented using the five interpreted results based on the confidence scores from the recognizer was Android specific. If you were to use a speech recognizer which only caught one input you would have lesser likely hood of finding perfect matches. However, as shown in the results, 12 out of 15 perfect matches was at the first position and this would likely not decrease the experience dramatically.

\subsection{Large Scale Requirements Engineering}
In the solution presented there is mainly one operation that has the biggest impact on the time efficiency in the system, the look up of the entities (the requirements). The results presented in section Large Scale Requirement Engineering (\ref{eval:lsre}) shows that the system scales very well. Even when querying large scale SRSs the user is provided feedback within seconds. The look-up is done very efficiently due to that the requirement entities are cached in both the SpeechServer and the SystemWeaver server. 

Direct improvements could be done to the edit distance calculation. As can be seen in section~\ref{sub:reqmatch}, 93\% of the sought requirements ended up in a top five ranking. From this information, you could make cuts in the calculations to have a dynamic roof for when you stop to calculate the distance, e.g.\ if the given input has a higher distance than the fifth element in the list, then it does not need to complete the run of the algorithm and can return infinity. 

\section{Speech Recognition}
This section discusses state-of-practice speech recognition. What lies in focus is the accuracy of, and found problems that are associated with, speech recognition. 
\subsection{Accuracy}
The requirement matching experiment (\ref{sub:reqmatch}) shows that a speech recognizer combined with a string edit distance algorithm can be used very efficiently in a closed domain such as an SRS with thousands of requirements. However, it was also found that the speech recognizer was not sufficient enough for providing descriptive text in terms of technical sentences (see \ref{subsec:recaccresult}). The experiemnt also showed that 10\% of the interpreted inputs could give another meaning to the SRS. This would be contradictive, and would lower rather than increase the quality of the SRS. 

\subsubsection{Problems Associated to Speech recognition}
Other problems was that the speech recognition had problems finding requirements that was misspelled, since the speech recognizer only provide words spelled correctly (thankfully). If there is only one requirement misspelled this is no problem for example: \emph{"re\emph{k}uirement"} only has a distance of 1 if the user sought for \emph{"requirement"} and would end up highest in the ranking. The problem arises when there are many requirements spelled correctly, but a few misspelled. e.g.\ \emph{"requirement 1"}, \emph{"requirement 2"}, \emph{"requirement 3"} and \emph{"re\emph{ck}uirement 4"}, then if the user sought for \emph{"requirement 4"}, then 1,2,3 would end up before 4 anyway. Moreover, the recognizer did not handle special characters and abbreviations in a satisfiable way. Due to the speech recognizer being built upon a spoken language (in this case English US) there were some homophone problems, e.g.\ the letter "C" was sometimes interpreted as "see". Another case was when two words are pronounced in the same way, such as "see" and "sea".

\subsection{Mobility}
Since today's smart devices have become powerful enough to have speech recognizers within them, something that was found during the product evaluation was that the mobility of the devices gave the advantage that you could maintain documentation from anywhere. Another thing that arose during the product evaluation was that it was a benefit to be able to connect annotations to the actual requirement immediately instead of having an icebox of updates to the system, separate from the system.

Since the speech recognition did not prove to be efficient for long descriptive sentences, other features of the smart devices were implemented. A smart device can take pictures, record movies or audio (such as interviews or short memos) and such information could compensate for the lack of efficiency from the speech recognizer. Direct solutions that were seen during this thesis were to attach notes/blueprints from white boards or from paper, as well as stating why a requirement needed to be updated with the origin from a recorded interview on the device. 

\section{Quality of SRSs and Requirements}
This sections will discuss impact on the quality of SRSs and requirements. It will present problems that was found during the thesis that has impact on the quality or continuous work with quality. The sections will also present metrics and possible solutions for how annotations can be used and what impact they can have on the quality aspect of an SRS.

\subsection{Duplicates in SRSs}
Problems encountered was that sometimes names of requirements were duplicated, although they were distinguishable from each other within SystemWeaver thanks to the structure of the items. This is however a problem with speech searching where there are no visual clues on the structure, they could be presented with their parent node appended with the title, but this would require extra work both in terms of development as well as computing time since the linking is only done in one way, one would have to traverse from the top and find the parent node. Examples of this could be \emph{"Gear 1 - Clutch should not * "} \emph{"Gear 2 - Clutch should not * "} and so on. Another way of solving this would be to force the requirement titles to be unique in the first place. This however needs much more maintenance effort, since these rules might be hard to follow, and might hinder the creation of requirements. This could be built into the RQ-database tool, but better searching and displaying is probably the better approach.

\subsection{Metrics}
The annotations can be aggregated and used in different metrics calculated continuously as well as periodically. These metrics could be used for checkpoints that could be either time driven or event driven, to do inspections of the requirements. These metrics can be presented and calculated as described in \citet{ieeemetrix}. These indicators can be used to trigger events, such as requirement specification reviews. An example could be if more than 10\% of the requirements are tagged as ambiguous, a review of the requirements should take place. These metrics could also be used in stage gates, e.g.\ before continuing to the next step all of specified annotation types must be resolved.

\subsection{How can Annotations Increase the Quality of SRSs}
If the product owner or requirement engineer receive feedback in the form of annotations, continuously in an agile fashion, that person can act upon these annotations immediately. If quality issues in a requirement are corrected at once, before others read and misinterpret the requirement, some quality issues in the product might be avoided. The annotations can be done continuously over a project, but also at certain review sessions, where the solution can be used as a review tool. This is also one of the most mentioned use cases during the interviews (see section~\ref{sec:prodeval}).

In a larger scale, this information can be helpful to do root cause analysis (RCA) and find out why these issues are introduced (lack of training, communication problems etc). This can be done using any RCA method, but an easy first step could be the 5-whys technique described by \citet{5whys}.

Another interesting analysis could be to see what requirements (or type of requirements) that have the most annotations (or a specific category of annotations) to see what requirements that have much problems, it could be that they are vague, or highly complex. If a requirement has many annotations and there seems to be much problem understanding it, actions can be taken to mitigate these problems by having formal or informal discussions about the requirement. 

\subsection{What can Annotations be Used for?}
\label{whatcanbeused}
If annotations are provided continuously during the lifetime of a project, the annotations can provide insight on when different quality issues occur. From this, trends could be seen for different annotations. This data can be useful to do analysis on the different annotations in the SRS. If one for example know that ambiguity is noticed when implementation has started, maybe effort can be done beforehand to reduce ambiguity. If it's known when different quality issues occur in projects it can be analyzed for project maturity status. 

The annotation data could possibly be used in a similar manner to how defect inflow can be predicted as described by \citet{mstaronmetrics}.

\section{Future work}
During the course of this thesis, several areas appeared that could be investigated in the future. In this section we present topic that we consider to be interesting to evaluate or implement.

\subsection{Investigate String Distance Algorithms for Speech Input Towards Technical Domains}
As described in Section~\ref{subsec:leved} work could be done to see what algorithms could be used to give more accurate rankings or faster results. Investigations could be done to see if algorithms in parallel give better results, or dynamic depending och content and length. There might be ways to customize algorithms for the particular domain as well.

\subsection{Enabling SRSs in Smartphones}
One byproduct of the thesis was the possibility of working with SRSs in smart phones with limited screen size. The application could be extended or other applications to include functionality operating with SRSs, such as finding information more rapidly. Users could ask the application for descriptions of specific requirements or finding any attributes of a requirement such as the owner/author of a requirement. This way, developers and testers can get fast reminders of requirements to always be up to date on current status.

\subsection{Create Custom Word Lists in Organizations, or Adapted Corpora}
Since problems was encountered related to language issues and speech recognition, we suggest that more work should to be done extracting organization specific language. Since there are differences in languages depending on what is common in different domains, the predictions can be made more accurate if all common domain specific words (and acronyms) are available in word lists as well as how they occur in natural language sentences. By having tailored corpora for different organizations the sentence and word predictions can be made better. 

\subsection{Investigate SRS Quality}
It is described in section~\ref{whatcanbeused} how annotations can be used, but work needs to be done to investigate what real data from a project would look like, and what further conclusions can be drawn from the annotations. It needs to be done over a longer period of time to see if any trends can be seen and if annotation statistics are generalizable. The same goes for annotation predictions. The proposed future work for these annotations are only a fraction of what might be possible once tried in a real project and it is likely that the annotations can be altered and used for other purposes.

\subsection{(Speech) Annotations for other Software Engineering Artefacts}
This paper focused on annotating requirements in an SRS, the same system could also work for less formal requirements, such as user stories in agile development. We also believe that more artifacts can benefit from lightweight, mobile and easy accessible tools. Other custom made tools for different tasks handling other (softer) software artifacts using similar technologies could be developed. These tools could be used by testers to report test statuses and notifications, it could be used in verification/validation to assign statuses and accept/decline parts of a system and so on. 


